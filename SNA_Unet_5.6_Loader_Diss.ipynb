{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a505418",
   "metadata": {},
   "source": [
    "# Seismic Noise Attenuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a8bcd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c975256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_range='525-725' # 15, 215\n",
    "# train_range='511-650' # 140 images ~ 1/2. last ones are bad so test on middle I guess\n",
    "# load_versions = [f'1.8.il{train_range}', f'1.9.il{train_range}', f'1.7.il{train_range}', f'1.10.il{train_range}']\n",
    "# load_version = f'1.9.il{train_range}' # change between il/xl, specify line number (not index)\n",
    "# numimg = 650-511+1\n",
    "\n",
    "# training_range = (0,63) # here we see the problem of naming a variable 'slice_img'... can't use slice_img()\n",
    "# train_range = str(training_range[0])+'-'+str(training_range[1]) # set up like this for compatibility with old plotting savefile titling\n",
    "# load_versions = [f'2.1.il{train_range}', f'2.3.il{train_range}', f'2.2.il{train_range}', f'2.4.il{train_range}']\n",
    "# load_versions_master = [f'2.1.il{train_range}', f'2.3.il{train_range}', f'2.2.il{train_range}', f'2.4.il{train_range}']\n",
    "# load_versions = [f'2.1.il{train_range}', f'2.3.il{train_range}', f'2.2.il{train_range}']\n",
    "# numimg = training_range[1]-training_range[0]+1\n",
    "\n",
    "train_range = '0-137'\n",
    "# numimg = 137\n",
    "numchan = 4\n",
    "# version = f'5.1.il{train_range}'\n",
    "# load_versions = [version]\n",
    "load_versions = [f'5.4.il{train_range}', f'5.5.il{train_range}', f'5.6.il{train_range}']\n",
    "\n",
    "method = 'DIP_SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a41a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 1\n",
    "if gpu == 1:\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(gpus)\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "elif gpu == 0:\n",
    "    print(\"Running on CPU only\")\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d57e41",
   "metadata": {},
   "source": [
    "all: 4 channel input/output\n",
    "1.8: No skip connections, 8941.155124902725 s,  ~8.9 s/e\n",
    "1.9: 1 skip connections, should have tensorboard histograms, 9748.246639490128 s, ~9.7 s/e\n",
    "1.7: 2 skip connections, 12417.962851285934 s, ~12.4 s/e\n",
    "1.10: 1 skip connection, trained on noisy (noise after norm), 9497.497680664062 s, ~9.5 s/e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9a9dc",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829039c0",
   "metadata": {},
   "source": [
    "### Load and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05efb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# import segyio\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f63a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '../Data/Swell/Train/'\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "input_data = []\n",
    "output_data = []\n",
    "for file_name in file_names:\n",
    "    path = directory + file_name\n",
    "    # print(f'Reading {path}')\n",
    "    stream = np.load(path)\n",
    "    slice_img = np.expand_dims(stream,0)\n",
    "    raw_shape = np.array(slice_img.shape)\n",
    "    # print(f'raw_shape {raw_shape}')\n",
    "    slice_img_shape = raw_shape//4*4        # desired shape\n",
    "    # slice_img_shape = np.array([1, 400, 592, 4])       # manual shape\n",
    "    # print(f'slice_img_shape {slice_img_shape}')\n",
    "    diff_shape = slice_img_shape-raw_shape   # mind first dimension if this input changes from 1 image\n",
    "    # print(f'diff_shape {diff_shape}')\n",
    "    \n",
    "    \n",
    "    if (diff_shape[1] != 0) & (diff_shape[2] != 0):\n",
    "        slice_img = slice_img[:, :diff_shape[1], :diff_shape[2]]\n",
    "    elif diff_shape[1] != 0:\n",
    "        slice_img = slice_img[:, :diff_shape[1], :]\n",
    "    elif diff_shape[2] != 0:\n",
    "        slice_img = slice_img[:, :, :diff_shape[2]]\n",
    "    else:\n",
    "        print(f'Data truncation error on file: {file_name}')\n",
    "\n",
    "    # print(f'File {file_name} fixed_shape {slice_img.shape}')\n",
    "    \n",
    "    if file_name.startswith(\"input\"):\n",
    "        input_data.append(slice_img)\n",
    "    elif file_name.startswith(\"output\"):\n",
    "        output_data.append(slice_img)\n",
    "    else:\n",
    "        print(f\"Unexpected file: {file_name}\")\n",
    "\n",
    "try:\n",
    "    input_data = np.concatenate(input_data, axis=0 )\n",
    "    output_data = np.concatenate(output_data, axis=0)\n",
    "except ValueError as e:\n",
    "    print(\"Varying input image dimensions not currently supported. Reshape images to fixed dimensions\")\n",
    "    \n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "\n",
    "nil0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9a0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # path = r\"C:\\Users\\fmdel\\OneDrive - University of Leeds\\2021 Sem 1\\HALLIBURTON\\Data\\Kerry3D.segy\"\n",
    "# path = '../Data/Kerry3D.segy'\n",
    "# with segyio.open(path,iline=73, xline=21) as segyfile: # il/xl specify fields to look for in the trace headers. The numbers here are different to my old code but work...\n",
    "#     data = segyio.tools.cube(segyfile)\n",
    "#     size_mb= data.nbytes/1024**2\n",
    "#     header = segyio.tools.wrap(segyfile.text[0])\n",
    "    \n",
    "# #     inlines = segyfile.ilines\n",
    "# #     crosslines = segyfile.xlines\n",
    "# #     twt = segyfile.samples + 1000\n",
    "# #     sr = segyio.tools.dt(segyfile)\n",
    "\n",
    "#     il, xl, t = segyfile.ilines, segyfile.xlines, segyfile.samples \n",
    "#     dt = t[1]-t[0] # don't bother with segyio.tools.dt(segyfile), it's in microseconds\n",
    "    \n",
    "# #     ntraces = segyfile.tracecount\n",
    "# #     nsamples = segyfile.samples.size\n",
    "#                             # These depend on how the data are slice_imgd, so I have commented them out until that stage\n",
    "#     nil, nxl, nt = data.shape\n",
    "#     ntr = segyfile.tracecount\n",
    "#     nil0, nil1 = 510, 796 # Min/max iline numbers. different to il[0], il[-1] (some external coordinate system)\n",
    "#     nxl0, nxl1 = 58, 792-3 # Min/max xline numbers. same as xl[0], xl[-1]. Added -3. Varying slice_img_dims not worth messing about with. keep manual\n",
    "#     nt0, nt1 = 0, 5004 # Min/max twt. same as t[0], t[-1]\n",
    "    \n",
    "# import pickle\n",
    "# with open('../Data/kerry_cube.pkl', 'wb') as file:\n",
    "#     pickle.dump(data,file)\n",
    "# print(f'data pickled')\n",
    "\n",
    "# data = data[:,:-3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc5456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# data = pickle.load(open('../Data/kerry_cube.pkl', 'rb'))\n",
    "# data = data[:,:-3,:]\n",
    "\n",
    "# nil0, nil1 = 510, 796 # Min/max iline numbers. different to il[0], il[-1] (some external coordinate system)\n",
    "# nxl0, nxl1 = 58, 792-3 # Min/max xline numbers. same as xl[0], xl[-1]. Added -3. Varying slice_img_dims not worth messing about with. keep manual\n",
    "# nt0, nt1 = 0, 5004 # Min/max twt. same as t[0], t[-1]\n",
    "# nil, nxl, nt = data.shape  # shape AFTER slicing off 3 lines\n",
    "# dt = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed9bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../Data/data_trunc.pkl', 'rb') as file:\n",
    "#     data = pickle.load(file)\n",
    "# nil0 = 0\n",
    "\n",
    "# import os\n",
    "# directory = '../Data/Mo_DeepRift_profiles/'\n",
    "# file_names = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shrink data to GPU\n",
    "\n",
    "# data = data[:,:,:data.shape[2]//2//2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8325242",
   "metadata": {},
   "source": [
    "##### [Debug]: View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a849172-ec7f-4b5d-8821-c30347c94dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(input_data, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78d1a7-0bbb-469c-8082-b7431d9d26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Percentage of values lying outside of clip range\"\n",
    "# num_std_clip = 20\n",
    "# xmax = num_std_clip*np.std(input_data[line_idx,:,:,chan])\n",
    "xmax = 1\n",
    "xmin = -xmax\n",
    "test = output_data.flatten()\n",
    "test[np.logical_or(test>=xmax,test<=xmin)].shape[0]/test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248771cb-2540-4201-8b75-5cd961692f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(output_data.flatten(), bins=100, range=(-1,1))\n",
    "plt.title('output_data_normalized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70e7f8-60bb-4c8d-ac9b-b6461989bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(input_data.flatten(), bins=100, range=(-1,1))\n",
    "plt.title('input_data_normalized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff2a38-fa96-445c-92a1-27a046c7bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_data[idx_end, :, :, chan] # want to keep timeseries as rows for fft, don't transpose\n",
    "ps = np.average(np.abs(np.fft.fft(image)), axis=0)\n",
    "freqs = np.fft.fftfreq(ps.size, 2*10**-3)\n",
    "idx = np.argsort(freqs)\n",
    "idx = idx[len(idx)//2:]\n",
    "plt.plot(freqs[idx], ps[idx])\n",
    "plt.title('raw input image power spectrum (assumed sampling)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5e29f-daf5-43fe-8d78-7583818a0b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"Percentage of values lying outside of clip range\"\n",
    "num_std_clip = 8\n",
    "# xmax = num_std_clip*np.std(input_data[line_idx,:,:,chan])\n",
    "test = input_data.flatten()\n",
    "xmax = num_std_clip*np.std(test)\n",
    "xmin = -xmax\n",
    "test[np.logical_or(test>=xmax,test<=xmin)].shape[0]/test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ceb96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line_idx = 137 # line to view\n",
    "chan = 0\n",
    "print(f'line number: {line_idx+nil0}')\n",
    "\n",
    "num_std_clip = 4\n",
    "gain = 4\n",
    "cbar_scale = 1/gain\n",
    "xmax = num_std_clip*np.std(input_data[line_idx,:,:,chan])\n",
    "# xmax = num_std_clip*np.std(data[line_idx,:,:]) # note np.std(slice_img) changes value slightly from previous line\n",
    "xmin = -xmax\n",
    "# plotdata = np.clip(data[line_idx,:,:], \n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(data[line_idx,:,:].T, aspect='auto', cmap='RdYlBu', vmin=-5, vmax=5)\n",
    "plt.imshow(input_data[line_idx,:,:,chan].T, aspect='auto', cmap='RdYlBu',\n",
    "           # vmin=xmin*cbar_scale, vmax=xmax*cbar_scale\n",
    "          )\n",
    "# plt.imshow(data[line_idx,:,:].T, aspect='auto', cmap='RdYlBu', vmin=xmin*cbar_scale, vmax=xmax*cbar_scale)\n",
    "plt.colorbar()\n",
    "plt.gray()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7494a",
   "metadata": {},
   "source": [
    "### Define Functions for Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d31560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "    \n",
    "def prepdata(data, scale_range, num_std_clip, numimg, numchan, i_start, noise_factor):\n",
    "    \"\"\"Minmax scaling, optional gaussian noise\"\"\"\n",
    "    # np.random.seed(999)\n",
    "    noise_seeds = np.random.choice(range(0,10000),1000, False)\n",
    "\n",
    "    dataset = np.empty(shape=(numimg//numchan, data.shape[1], data.shape[2], numchan))\n",
    "    i = i_start\n",
    "    while i < numimg + i_start:\n",
    "        slice_img = data[i,:,:]\n",
    "        slice_img = slice_img - np.mean(slice_img)\n",
    "        # slice_img = slice_img + noise_factor*np.random.normal(loc=0.0, scale=np.std(slice_img), size=slice_img.shape)  # noise\n",
    "        xmax = num_std_clip*np.std(slice_img) # note np.std(slice_img) changes value slightly from previous line\n",
    "        xmin = -xmax\n",
    "\n",
    "        slice_img = scale_range[0]+((slice_img-xmin)*(scale_range[1]-scale_range[0]))/(xmax - xmin)\n",
    "             \n",
    "        if noise_factor != 0:\n",
    "            np.random.seed(noise_seeds[i])\n",
    "            slice_img = slice_img + noise_factor*np.random.normal(loc=0.0, scale=np.std(slice_img), size=slice_img.shape)  # noise\n",
    "\n",
    "        dataset[(i-i_start)//numchan, :, :, (i-i_start)%numchan] = slice_img\n",
    "        # print(i)\n",
    "        # print(f\"{(i-i_start)//numchan}, :, :, {(i-i_start)%numchan}\")   \n",
    "        i += 1\n",
    "    # i_start_test = i\n",
    "    dataset = dataset.astype('float32')\n",
    "    return(dataset, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017e0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# import cv2\n",
    "\n",
    "def num_elements(array):\n",
    "    size = 1\n",
    "    for dim in np.shape(array):\n",
    "        size *= dim\n",
    "    return size\n",
    "\n",
    "# def saltpepper(array, factor_pixels_corrupted, scale_range):\n",
    "#     # noise_seeds = np.random.choice(range(0,10000),1000, False)\n",
    "#     total_pixels = num_elements(array)\n",
    "#     num_pixles_corrupted = int(total_pixels*factor_pixels_corrupted)\n",
    "#     pixel_idx = np.random.choice(range(0,total_pixels-1), num_pixles_corrupted, False)\n",
    "#     black_idx = pixel_idx[:len(pixel_idx)//2]\n",
    "#     white_idx = pixel_idx[len(pixel_idx)//2:len(pixel_idx)//2*2]\n",
    "#     array_corrupted = array.flatten()\n",
    "#     for i in black_idx:\n",
    "#         array_corrupted[i] = scale_range[0]\n",
    "#     for i in white_idx:\n",
    "#         array_corrupted[i] = scale_range[1]    \n",
    "#     array_corrupted = array_corrupted.reshape(array.shape).astype('float32')\n",
    "    \n",
    "#     return(array_corrupted)\n",
    "\n",
    "def saltpepper(array, max_factor_pixels_corrupted, scale_range):\n",
    "    \"\"\"Replace random number of pixels (up to a cutoff) with salt and pepper\"\"\"\n",
    "    # noise_seeds = np.random.choice(range(0,10000),1000, False)\n",
    "    total_pixels = num_elements(array)\n",
    "    num_pixles_corrupted = np.random.randint(low=0, high=total_pixels*max_factor_pixels_corrupted)\n",
    "    pixel_idx = np.random.choice(range(0,total_pixels-1), num_pixles_corrupted, False)\n",
    "    black_idx = pixel_idx[:len(pixel_idx)//2]\n",
    "    white_idx = pixel_idx[len(pixel_idx)//2:len(pixel_idx)//2*2]\n",
    "    array_corrupted = array.flatten()\n",
    "    for i in black_idx:\n",
    "        array_corrupted[i] = scale_range[0]\n",
    "    for i in white_idx:\n",
    "        array_corrupted[i] = scale_range[1]    \n",
    "    array_corrupted = array_corrupted.reshape(array.shape).astype('float32')\n",
    "    \n",
    "    return(array_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class sp_generator(Sequence):\n",
    "    \"\"\"Generates randomized salt and peppered input images, Keras-style\"\"\"\n",
    "    \n",
    "    def __init__(self, array, to_fit, numchan=1, batch_size=1):\n",
    "        self.array = array\n",
    "        self.to_fit = to_fit\n",
    "        self.numchan = numchan\n",
    "        self.batch_size = batch_size\n",
    "        # self.shuffle = shuffle # needs to be in the init params if used # shouldn't make a difference, not using batches\n",
    "        self.on_epoch_end() #\n",
    "        self.indexes = np.arange(len(self.array))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.array))) # first dimension of data needs to be image idx but it should already be\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\"\"\"\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        x = saltpepper(self.array[index], factor_pixels_corrupted, scale_range)\n",
    "        if self.to_fit:\n",
    "            y = self.array\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # self.indexes = np.arange(len(self.array)) # randomize order of images within a batch\n",
    "        # if self.shuffle == True:\n",
    "        #     np.random.shuffle(self.indexes)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebac67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def sp_generator_sat(array,  factor_pixels_corrupted, scale_range, steps_per_epoch, numchan, batch_size):\n",
    "    \"Do the same thing but as a function\"\n",
    "    epochn = initial_epoch\n",
    "    counter = 0\n",
    "    while True:\n",
    "        for batch in range(batch_size):\n",
    "            counter += 1\n",
    "            x = saltpepper(array[counter-1], factor_pixels_corrupted, scale_range)\n",
    "            y = array\n",
    "            if counter ==(steps_per_epoch):\n",
    "                epochn += 1\n",
    "                counter=0\n",
    "        yield x, y\n",
    "        \n",
    "def sp_input_sat(array,  factor_pixels_corrupted, scale_range, steps_per_epoch, numchan, batch_size):\n",
    "    dataset = tf.Dataset.from_generator(lambda: sp_generator_sat(array,  factor_pixels_corrupted, scale_range, steps_per_epoch, numchan, batch_size),\n",
    "                                        output_types=(tf.float32, tf.float32),\n",
    "                                       )\n",
    "    dataset = dataset.batch(1)\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b3572-5fb0-47dc-95ed-ce5d5c989e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swell_generator(x_array, y_array):\n",
    "    # epoch = initial_epoch\n",
    "    indexes = np.arange(len(x_array))\n",
    "    # counter = 0\n",
    "    while True:\n",
    "        # counter += 1\n",
    "        index = np.random.choice(indexes)\n",
    "        x = x_array[index,:,:,:]\n",
    "        y = y_array[index,:,:,:]\n",
    "        # if counter ==(steps_per_epoch):\n",
    "        #         epochn += 1\n",
    "        #         counter=0\n",
    "        yield x, y\n",
    "    \n",
    "def swell_input(x_array, y_array):\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: swell_generator(x_array, y_array), output_types=(tf.float32, tf.float32))\n",
    "    dataset = dataset.batch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5cdaa",
   "metadata": {},
   "source": [
    "### Pre-Generate Train/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720100e",
   "metadata": {},
   "source": [
    "If a generator is used in the training, these simply call the functions above required to minmax scale and segment the \"clean\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda608c-aa72-4662-9d94-02567eec5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Minmax scale train dataset Satdat (Version 5)\"\"\"\n",
    "num_std_clip = 8\n",
    "scale_range = [-1,1]\n",
    "\n",
    "# input_data_scaled = np.empty(input_data.shape)\n",
    "# for i in range(input_data.shape[0]):\n",
    "#     for l in range(input_data.shape[-1]):\n",
    "#         slice_img = input_data[i,:,:,l]\n",
    "#         slice_img = slice_img - np.mean(slice_img)\n",
    "#         xmax = num_std_clip*np.std(slice_img) # note np.std(slice_img) changes value slightly from previous line\n",
    "#         xmin = -xmax\n",
    "#         slice_img = scale_range[0]+((slice_img-xmin)*(scale_range[1]-scale_range[0]))/(xmax - xmin)\n",
    "#         input_data_scaled[i,:,:,l] = slice_img\n",
    "        \n",
    "# output_data_scaled = np.empty(input_data.shape)\n",
    "# for i in range(output_data.shape[0]):\n",
    "#     for l in range(output_data.shape[-1]):\n",
    "#         slice_img = output_data[i,:,:,l]\n",
    "#         slice_img = slice_img - np.mean(slice_img)\n",
    "#         xmax = num_std_clip*np.std(slice_img) # note np.std(slice_img) changes value slightly from previous line\n",
    "#         xmin = -xmax\n",
    "#         slice_img = scale_range[0]+((slice_img-xmin)*(scale_range[1]-scale_range[0]))/(xmax - xmin)\n",
    "#         output_data_scaled[i,:,:,l] = slice_img\n",
    "\n",
    "# input_data = input_data_scaled\n",
    "# input_data_scaled = None\n",
    "\n",
    "# output_data = output_data_scaled\n",
    "# output_data_scaled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913cd06f-d681-4230-a5da-d0bc42bbb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"optional to reshape to 1 channel input\"\"\"\n",
    "input_data1 = np.reshape(input_data.transpose(0,3,1,2), input_data.shape[:3]*np.array([4,1,1]), order='C')\n",
    "input_data1 = np.expand_dims(input_data1, axis=3)\n",
    "\n",
    "output_data1 = np.reshape(output_data.transpose(0,3,1,2), output_data.shape[:3]*np.array([4,1,1]), order='C')\n",
    "output_data1 = np.expand_dims(output_data1, axis=3)\n",
    "\n",
    "input_data1 = input_data1[:-3,:,:,:]\n",
    "output_data1 = output_data1[:-3,:,:,:]\n",
    "\n",
    "# 4 channel input not renamed\n",
    "\n",
    "\"\"\"Generate train/test datasets Satdat (Version 5)\"\"\"\n",
    "# x_train = input_data[:-1,:,:,:]\n",
    "# y_train = output_data[:-1,:,:,:]\n",
    "# x_train1 = input_data1[:-1,:,:,:]\n",
    "# y_train1 = output_data1[:-1,:,:,:]\n",
    "x_test = input_data[-1,:,:,:]\n",
    "y_test = output_data[-1,:,:,:]\n",
    "x_test1 = input_data1[-1,:,:,:]\n",
    "y_test1 = output_data1[-1,:,:,:]\n",
    "x_test = np.expand_dims(x_test, axis=0)\n",
    "y_test = np.expand_dims(y_test, axis=0)\n",
    "x_test1 = np.expand_dims(x_test1, axis=0)\n",
    "y_test1 = np.expand_dims(y_test1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0ffea-9c75-495f-9e45-586bc72b0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # to ensure exactly the same image is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71132c-a8ec-4924-851f-caa799f71df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape, y_test.shape, x_test1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3910d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Generate train/test datasets Kerry3D (Version 1)\"\"\"\n",
    "# # scale_range, num_std_clip, numimg, numchan, i_start, noise_factor\n",
    "# # x_test, idx_end = prepdata(data, [-1,1], 4, training_range[1]-training_range[0]+1, 1, 0, 0)  # elaradat\n",
    "\n",
    "# x_train, idx_end = prepdata(data, [-1,1], 4, numimg, 4, 1, 0)  # kerry3d (1.7-1.9)\n",
    "# x_train_noisy, _ = prepdata(data, [-1,1], 4, numimg, 4, 1, 1)  # kerry3d (1.10)\n",
    "\n",
    "# x_test, _ = prepdata(data, [-1,1], 4, 8, 4, idx_end, 0)  # kerry3d (1.7-1.9)\n",
    "# x_test_noisy, _ = prepdata(data, [-1,1], 4, 8, 4, idx_end, 1)  # kerry3d (1.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0bece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Generate train/test datasets elaradat (Version 2)\"\"\"\n",
    "# x_train, idx_end = prepdata(data, [-1,1], 4, numimg, 1, 0, 0)  # elaradat (2.1-2.4)\n",
    "# x_train_noisy, _ = prepdata(data, [-1,1], 4, numimg, 1, 0, 1)  # elaradat (2.1-2.4)\n",
    "\n",
    "# # x_test, _ = prepdata(data, [-1,1], 4, 4, 1, idx_end, 0)  # elaradat (2.1-2.4)    # changed to 1 test image for gif\n",
    "# # x_test_noisy, _ = prepdata(data, [-1,1], 4, 4, 1, idx_end, 1)  # elaradat (2.1-2.4)\n",
    "# x_test, _ = prepdata(data, [-1,1], 4, 8, 1, idx_end, 0)  # elaradat (2.1-2.4)    # changed to 8 test images\n",
    "# x_test_noisy, _ = prepdata(data, [-1,1], 4, 8, 1, idx_end, 1)  # elaradat (2.1-2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b06198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Generate single image elaradat (Version 4)\"\"\"\n",
    "# scale_ranges = [[-1,1]]\n",
    "# scale_range = scale_ranges[0]\n",
    "# x_train, _ = prepdata(data, [-1,1], 4, numimg, 1, 70, 0)  # elaradat (2.1-2.4)\n",
    "# idx_end = 0\n",
    "# # x_train_noisy, _ = saltpepper(x_train, )  # elaradat (2.1-2.4)\n",
    "\n",
    "# x_test = x_train\n",
    "# x_tests = [x_test]\n",
    "# # x_test_noisy, _ = prepdata(data, [-1,1], 4, 4, 1, idx_end, 1)  # elaradat (2.1-2.4)\n",
    "\n",
    "# data = np.empty(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1f6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale_ranges = [[-1,1], [-1,1], [-1,1], [-1,1]]\n",
    "# # x_tests = [x_test_noisy, x_test_noisy, x_test_noisy, x_test_noisy]\n",
    "# x_tests = [x_test, x_test, x_test, x_test]\n",
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562737c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train_noisy = x_train_noisy.astype('float32')\n",
    "# x_test_noisy = x_test_noisy.astype('float32')\n",
    "# print(f'Training set shape: {np.shape(x_train)}')\n",
    "# print(f'Testing set shape: {np.shape(x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdb21d",
   "metadata": {},
   "source": [
    "#### [Debug]: Verify with plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=64\n",
    "\n",
    "# slice_img = data[i,:,:]\n",
    "# slice_img = slice_img - np.mean(slice_img)\n",
    "# # slice_img = slice_img + noise_factor*np.random.normal(loc=0.0, scale=np.std(slice_img), size=slice_img.shape)  # noise\n",
    "# xmax = 4*np.std(slice_img) # note np.std(slice_img) changes value slightly from previous line\n",
    "# xmin = -xmax\n",
    "\n",
    "# slice_img = scale_range[0]+((slice_img-xmin)*(scale_range[1]-scale_range[0]))/(xmax - xmin)\n",
    "# plt.imshow(slice_img[:,:].T, aspect='auto', vmin=-0.1, vmax=0.1)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3b590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gain = 100\n",
    "# cbar_scale = 1/gain\n",
    "\n",
    "# fig, axes = plt.subplots(4,2, figsize=(12, 8))\n",
    "\n",
    "# for i in range(x_test.shape[0]):\n",
    "#     plt.subplot(4,2,i+1)\n",
    "#     plt.imshow(x_test[i,:,:,0].T,\n",
    "#                cmap='RdYlBu', \n",
    "#                vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale\n",
    "#               )\n",
    "#     plt.gray()\n",
    "#     plt.colorbar()\n",
    "#     plt.axis('tight')\n",
    "#     plt.title(epochs[i])\n",
    "\n",
    "\n",
    "# # plt.imshow(x_train[0,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# # plt.colorbar()\n",
    "# # plt.gray()\n",
    "# # plt.tight_layout()\n",
    "# # plt.title(f'{file_names[line_num]} normalized to {scale_range}, gain of {gain}') \n",
    "# # plt.savefig(f'elaradat_{line_num}_norm_resize')\n",
    "# plt.savefig('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67c67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# line_num = 10 # line to view\n",
    "# gain = 5\n",
    "# cbar_scale = 1/gain\n",
    "# scale_range = scale_ranges[0]\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(x_train[line_num,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.colorbar()\n",
    "# plt.gray()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.figure(figsize=(12, 8))\n",
    "# # plt.imshow(all_clean_images[2][19,line_num,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# # plt.colorbar()\n",
    "# # plt.gray()\n",
    "# # plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df5598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# line_num = 0 # line to view\n",
    "# gain = 5\n",
    "# cbar_scale = 1/gain\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(x_train[line_num,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.colorbar()\n",
    "# plt.gray()\n",
    "# plt.tight_layout()\n",
    "# plt.title(f'{file_names[line_num]} normalized to {scale_range}, gain of {gain}') \n",
    "# plt.savefig(f'elaradat_{line_num}_norm_resize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551be041",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f19589-d603-4649-aa35-d50db2d88a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = None\n",
    "data = np.empty(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8748ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # if model did not reach savepoint: generate architecture\n",
    "# import os\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# from keras import layers\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "# tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "\n",
    "# input_img = keras.Input(shape=(data.shape[1], data.shape[2], numchan))                            # put shape = none ?\n",
    "# act= tf.keras.layers.LeakyReLU()                                         # default 0.3 negative slope throughout. Consider changing???\n",
    "# conv1 = layers.Conv2D(64, (3,3), activation=act, padding='same', name='conv1')(input_img)    # conv\n",
    "# enc1 = layers.Conv2D(32, (3,3), strides=(2,2), padding='same', name='enc1')(conv1)           # informed downsampling\n",
    "# conv2 = layers.Conv2D(32, (3,3), activation=act, padding='same', name='conv2')(enc1)         # conv\n",
    "# enc2 = layers.Conv2D(32, (3,3), strides=(2,2), padding='same', name='enc2')(conv2)      # informed downsampling\n",
    "\n",
    "# conv3 = layers.Conv2D(32, (3,3), activation=act, padding='same', name='bottleneck')(enc2)   # latent space\n",
    "# dec1 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), activation=act, padding='valid', name='dec1')(conv3)\n",
    "# skip1 = layers.Concatenate()([dec1, conv2]) # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# conv4 = layers.Conv2D(32, (3,3), activation=act, padding='same', name='conv4')(skip1)\n",
    "# dec2 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), activation=act, padding='valid', name='dec2')(conv4)\n",
    "# # skip2 = layers.Concatenate()([dec2, conv1]) # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# conv5 = layers.Conv2D(64, (3,3), activation=act, padding='same', name='conv5')(dec2) \n",
    "\n",
    "# output = layers.Conv2D(numchan, (3, 3), activation='linear', padding='same')(conv5)\n",
    "\n",
    "# Unet = keras.Model(input_img, output)\n",
    "# Unet.compile(optimizer='adam', loss='mse', metrics=['mae']) # The quantity to be monitored for early stopping needs to be available in logs dict. To make it so, pass the loss or metrics here\n",
    "\n",
    "# loaded_model = Unet\n",
    "# Unet = None\n",
    "# loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1de38",
   "metadata": {},
   "source": [
    "# Prepare Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47cc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.makedirs('Logs', exist_ok=True)\n",
    "# # os.makedirs(f'./Logs/{version}', exist_ok=True)  # was a bit silly to do the folders this way, but ah well. Should probably make an info file each run. For now keep changelog\n",
    "# os.makedirs(f'./Logs/checkpoints_{version}', exist_ok=True)\n",
    "# os.makedirs(f'./Logs/TBlog_{version}', exist_ok=True)\n",
    "# # os.makedirs(f'./Logs/csvlog_{version}', exist_ok=True)\n",
    "\n",
    "# # ckpt_filepath = './Logs/checkpoints_{}/ckpt-{epoch:02d}.hdf5'.format(version)\n",
    "# pathstart = './Logs/checkpoints_{}/'.format(version)\n",
    "# pathend = 'ckpt-{epoch:02d}.hdf5'\n",
    "# ckpt_filepath = pathstart + pathend\n",
    "\n",
    "# # checkpoint_filepath = f'C:\\Python\\Python39\\Scripts\\modelCheckpoints\\checkpoints_{version}' # is there any reason not to move this somewhere more consistent with the rest??? Need to email Mryga about checkpoints.\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     # filepath='./Logs/checkpoints_1.7.il511-650/ckpt-{epoch:02d}.hdf5',\n",
    "#     filepath = ckpt_filepath,\n",
    "#     # save_weights_only=False,\n",
    "#     save_weights_only=True,\n",
    "#     monitor=('loss'),\n",
    "#     mode='max',\n",
    "#     save_freq='epoch',\n",
    "#     verbose=1,\n",
    "#     # period=10 # deprecated for some reason\n",
    "#     save_best_only=False, # want to save full model every x epochs to print image\n",
    "# )\n",
    "\n",
    "# tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=f'./Logs/TBlog_{version}', write_graph=True, write_images=True)\n",
    "# csvlogger_callback = tf.keras.callbacks.CSVLogger(f'./Logs/csvlog_{version}.csv', separator=',', append=False)\n",
    "# # early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268f740",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ce713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"5.0\"\"\"\n",
    "# # import pydot\n",
    "# # import pydotplus\n",
    "# # tf.keras.utils.plot_model(loaded_model, show_shapes=True, show_layer_names=True)\n",
    "# # tf.keras.utils.plot_model(loaded_model, to_file= f'./{version}_arch.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# initial_epoch = 1\n",
    "\n",
    "# callbacks=[model_checkpoint_callback,\n",
    "#            tensor_board_callback,\n",
    "#            csvlogger_callback,\n",
    "#            # early_stopping_callback,\n",
    "#           ]\n",
    "# swell_input\n",
    "# import keras\n",
    "# tf.keras.backend.clear_session()\n",
    "# # reset_keras()\n",
    "# start_time = time.time()\n",
    "# try:\n",
    "#     history=loaded_model.fit(\n",
    "#                     # x=x_train, y=y_train, # update saltpepper to output x_train, get rid of y\n",
    "#                     swell_input(x_train, y_train),\n",
    "#                     steps_per_epoch = x_train.shape[0],\n",
    "#                     validation_data=(x_test, y_test),\n",
    "#                     epochs=20000,\n",
    "#                     callbacks=callbacks,        \n",
    "#                     use_multiprocessing=True, # Note using this makes keras expect a generator\n",
    "#                     # workers=8,\n",
    "#                             )\n",
    "                            \n",
    "# # try:\n",
    "# #     history=loaded_model.fit_generator(generator=training_generator,\n",
    "# #                     validation_data=validation_generator,\n",
    "# #                     use_multiprocessing=True,\n",
    "# #                     workers=8,\n",
    "# #                     epochs=1000,\n",
    "# #                     callbacks=callbacks)\n",
    "# except KeyboardInterrupt:\n",
    "#     tf.keras.backend.clear_session()\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time-start_time\n",
    "# print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccd72a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Just calls saltpepper function to prep a single image for DIP\"\"\"\n",
    "# import pydot\n",
    "# import pydotplus\n",
    "# tf.keras.utils.plot_model(loaded_model, show_shapes=True, show_layer_names=True)\n",
    "# tf.keras.utils.plot_model(loaded_model, to_file= f'./{version}_arch.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# model_idx=0\n",
    "# max_factor_pixels_corrupted = 0.1\n",
    "# scale_range = scale_ranges[model_idx]\n",
    "# x_test = x_tests[model_idx]\n",
    "\n",
    "# callbacks=[model_checkpoint_callback,\n",
    "#            tensor_board_callback,\n",
    "#            csvlogger_callback,\n",
    "#            # early_stopping_callback,\n",
    "#           ]\n",
    "\n",
    "# import keras\n",
    "# tf.keras.backend.clear_session()\n",
    "# # reset_keras()\n",
    "# start_time = time.time()\n",
    "# try:\n",
    "#     history=loaded_model.fit(x=saltpepper(x_train, max_factor_pixels_corrupted, scale_range), y=x_train, # update saltpepper to output x_train, get rid of y\n",
    "#                     validation_data=(saltpepper(x_train, max_factor_pixels_corrupted, scale_range), x_test),\n",
    "#                     epochs=1000,\n",
    "#                     callbacks=callbacks,        \n",
    "#                     use_multiprocessing=True,\n",
    "#                     # workers=8,\n",
    "#                             )\n",
    "                            \n",
    "# # try:\n",
    "# #     history=loaded_model.fit_generator(generator=training_generator,\n",
    "# #                     validation_data=validation_generator,\n",
    "# #                     use_multiprocessing=True,\n",
    "# #                     workers=8,\n",
    "# #                     epochs=1000,\n",
    "# #                     callbacks=callbacks)\n",
    "# except KeyboardInterrupt:\n",
    "#     tf.keras.backend.clear_session()\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time-start_time\n",
    "# print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f3780",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad45b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import model_from_json\n",
    "Unet_json = loaded_model.to_json()         # save architecture\n",
    "with open(f\"Unet_{version}.json\", \"w\") as json_file:\n",
    "    json_file.write(Unet_json)\n",
    "# serialize weights to HDF5\n",
    "loaded_model.save_weights(f\"Unet_{version}.h5\")       # save weights\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddc847",
   "metadata": {},
   "source": [
    "## Call Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe89f1",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbcd80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load loss\n",
    "import pandas as pd\n",
    "loss_dfs = []\n",
    "for load_version in load_versions:\n",
    "    loss_df = pd.DataFrame(pd.read_csv(f'./Logs/csvlog_{load_version}.csv'))\n",
    "    loss_df.set_index('epoch')\n",
    "    loss_dfs.append(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e77ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb55831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# descriptions = ['L2, no skip', 'L2, bottom skip', 'L2, both skip', 'L2, bottom skip, syn noise']\n",
    "# descriptions = ['L2, no skip', 'L2, bottom skip', 'L1, bottom skip', 'L1, both skip']\n",
    "# descriptions = ['L1, bottom skip']\n",
    "descriptions = ['MSE loss, 1 channel', 'MSE loss, 4 channels', 'MAE loss, 4 channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.rcParams.update(plt.rcParamsDefault)\n",
    "# fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "# for i in range(len(load_versions)):\n",
    "#     loss_df = loss_dfs[i]\n",
    "#     ax = axes.flatten()[i]\n",
    "#     ax.plot(loss_df['loss'])\n",
    "#     # ax.plot(loss_df['val_loss'])\n",
    "#     ax.set_ylabel('loss')\n",
    "#     ax.set_xlabel('epoch')\n",
    "#     # ax.legend(['train', 'test'], loc='upper left')\n",
    "#     # ax.set_title(load_versions[i][0:4])\n",
    "#     ax.set_xlim(-10,310)\n",
    "#     ax.set_title(load_versions[i][0:4] + ': ' + descriptions[i])\n",
    "#     ax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.suptitle('Kerry3D loss', y=1.02)\n",
    "# plt.show()\n",
    "# # plt.savefig("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298ca31-e987-4156-97a9-3242cf784666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"duplicates loss column to a new column with appropriate metric title for easier plotting\"\"\"\n",
    "loss_dfs[0]['mse'] = loss_dfs[0].loc[:,'loss']\n",
    "loss_dfs[1]['mse'] = loss_dfs[1].loc[:,'loss']\n",
    "loss_dfs[0]['val_mse'] = loss_dfs[0].loc[:,'val_loss']\n",
    "loss_dfs[1]['val_mse'] = loss_dfs[1].loc[:,'val_loss']\n",
    "\n",
    "loss_dfs[2]['mae'] = loss_dfs[2].loc[:,'loss']\n",
    "loss_dfs[2]['val_mae'] = loss_dfs[2].loc[:,'val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea623f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Plot on same plot with legend\"\"\"\n",
    "# x_lim = (-10, 310)\n",
    "max_x_lim = 1000\n",
    "x_lim = (-max_x_lim/50, max_x_lim)\n",
    "# x_lim=(-50, 1050)\n",
    "loss_tag = 'val_mae'\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "for i in range(len(load_versions)):\n",
    "    loss_df = loss_dfs[i]\n",
    "    ax = axes.flatten()[0]\n",
    "    ax.plot(loss_df[loss_tag], linewidth=0.5)\n",
    "    # ax.plot(loss_df['val_loss'])\n",
    "    ax.set_ylabel(loss_tag)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(descriptions)\n",
    "    # ax.set_title('loss')\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    \n",
    "    # ax.set_title(load_versions[i][0:4] + ': ' + descriptions[i])\n",
    "    # ax.ticklabel_format(useOffset=False, style='plain')\n",
    "    \n",
    "    ax = axes.flatten()[-1]\n",
    "    ax.plot(loss_df[loss_tag], linewidth=0.5)\n",
    "    # ax.plot(loss_df['val_loss'])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(loss_tag)\n",
    "    ax.set_xlabel('epoch')\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.legend(descriptions)\n",
    "    # ax.set_title('log loss')\n",
    "\n",
    "# ax.legend([str(load_versions[0][0:3])])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.suptitle('Swelldat Supervised Learning Metrics', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46744324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
    "# loss_df = loss_dfs[i]\n",
    "# ax.plot(loss_df['loss'])\n",
    "# # ax.plot(loss_df['val_loss'])\n",
    "# # ax.set_yscale('log')\n",
    "# ax.set_ylabel('loss')\n",
    "# ax.set_xlabel('epoch')\n",
    "# ax.set_xlim(-10,310)\n",
    "# ax.set_title(load_versions[i][0:4] + ': ' + descriptions[i])\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.suptitle('Mo DeepRift L1 loss', y=1.02)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f115d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.rcParams.update(plt.rcParamsDefault)\n",
    "# fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "# for i in range(len(load_versions)):\n",
    "#     loss_df = loss_dfs[i]\n",
    "#     ax = axes.flatten()[i]\n",
    "#     ax.plot(loss_df['loss'])\n",
    "#     # ax.plot(loss_df['val_loss'])\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_ylabel('loss')\n",
    "#     ax.set_xlabel('epoch')\n",
    "#     # ax.legend(['train', 'test'], loc='upper left')\n",
    "#     # ax.set_title(load_versions[i][0:4])\n",
    "#     ax.set_xlim(-10,310)\n",
    "#     ax.set_title(load_versions[i][0:4] + ': ' + descriptions[i])\n",
    "#     # ax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.suptitle('Kerry3D log loss', y=1.02)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5942e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.rcParams.update(plt.rcParamsDefault)\n",
    "# fig, ax = plt.subplots(figsize=(4,4))\n",
    "# legend = []\n",
    "# for i in range(len(load_versions)):\n",
    "#     loss_df = loss_dfs[i]\n",
    "#     ax.plot(loss_df['loss'], linewidth=1)\n",
    "#     # ax.plot(loss_df['val_loss'])\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_ylabel('loss')\n",
    "#     ax.set_xlabel('epoch')\n",
    "#     # ax.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "#     # ax.set_title(load_versions[i][0:4])\n",
    "#     ax.set_xlim(-10,1010)\n",
    "#     ax.set_ylim(10**-7,10**-1)\n",
    "#     # ax.set_title(load_versions[i][0:4] + ': ' + descriptions[i])\n",
    "#     # ax.ticklabel_format(useOffset=False, style='plain')\n",
    "#     legend.append((load_versions[i][0:4]))\n",
    "# ax.legend(legend)\n",
    "# fig.tight_layout()\n",
    "# # plt.suptitle('Kerry3D log loss', y=1.02)\n",
    "# plt.title('Kerry3D log loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63942815",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5435c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import model_from_json\n",
    "\n",
    "# loaded_models = []\n",
    "# for load_version in load_versions:\n",
    "#     json_file = open(f'Unet_{load_version}.json', 'r')\n",
    "#     loaded_model_json = json_file.read()\n",
    "#     json_file.close()                         \n",
    "#     loaded_model = model_from_json(loaded_model_json)  \n",
    "#     # loaded_model.load_weights(f'Unet_{load_version}.h5')\n",
    "    \n",
    "#     loaded_models.append(loaded_model)\n",
    "#     print(f'Loaded {load_version}')\n",
    "    \n",
    "#     # loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ee2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def load_model(load_version):\n",
    "    i = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "    json_file = open(f'Unet_{load_version}.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()                         \n",
    "    loaded_model = model_from_json(loaded_model_json)  \n",
    "    print(f'Loaded {load_version}')\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799cf4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    # if load_versions[i] == '2.1.il0-63':\n",
    "    #     loaded_model.compile(optimizer='adam', loss='mse', metrics = ['mean_absolute_error'])\n",
    "    # elif load_versions[i] == '2.3.il0-63':\n",
    "    #     loaded_model.compile(optimizer='adam', loss='mse', metrics = ['mean_absolute_error'])\n",
    "    # elif load_versions[i] == '2.2.il0-63':\n",
    "    #     loaded_model.compile(optimizer='adam', loss='mae', metrics = ['mean_squared_error'])\n",
    "    # elif load_versions[i] == '2.4.il0-63':\n",
    "    #     loaded_model.compile(optimizer='adam', loss='mae', metrics = ['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models[0].compile(optimizer='adam', loss='mse', metrics = ['mean_absolute_error'])\n",
    "# loaded_models[1].compile(optimizer='adam', loss='mse', metrics = ['mean_absolute_error'])\n",
    "# loaded_models[2].compile(optimizer='adam', loss='mae', metrics = ['mean_squared_error'])\n",
    "# loaded_models[3].compile(optimizer='adam', loss='mae', metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fd157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_version = load_versions[3]\n",
    "# numchan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22915be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 199\n",
    "loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc77351",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b5d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# version = load_version\n",
    "\n",
    "# pathstart = './Logs/checkpoints_{}/'.format(version)\n",
    "# pathend = 'ckpt-{epoch:02d}.hdf5'\n",
    "# ckpt_filepath = pathstart + pathend\n",
    "\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     # filepath='./Logs/checkpoints_1.7.il511-650/ckpt-{epoch:02d}.hdf5',\n",
    "#     filepath = ckpt_filepath,\n",
    "#     # save_weights_only=False,\n",
    "#     save_weights_only=True,\n",
    "#     monitor=('loss'),\n",
    "#     mode='max',\n",
    "#     save_freq='epoch',\n",
    "#     verbose=1,\n",
    "#     # period=10 # deprecated for some reason\n",
    "#     save_best_only=False, # want to save full model every x epochs to print image\n",
    "# )\n",
    "\n",
    "# tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=f'./Logs/TBlog_{version}', write_graph=True, write_images=True)\n",
    "# csvlogger_callback = tf.keras.callbacks.CSVLogger(f'./Logs/csvlog_{version}.csv', separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcbd37",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import pydot\n",
    "# import pydotplus\n",
    "# # tf.keras.utils.plot_model(Unet, show_shapes=True, show_layer_names=True)\n",
    "# # tf.keras.utils.plot_model(Unet, to_file= f'./{version}_arch.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# import keras\n",
    "# tf.keras.backend.clear_session()\n",
    "# # reset_keras()\n",
    "# start_time = time.time()\n",
    "# try:\n",
    "#     history=loaded_model.fit(x_train, x_train,\n",
    "#                     epochs=3,\n",
    "# #                 epochs=5000,\n",
    "# #                 batch_size=2,        # c.f. discussion on batch size\n",
    "#                     batch_size=1,\n",
    "#                     shuffle=True,        # shuffles whole dataset, not within batches\n",
    "# #                 shuffle=False,\n",
    "#                     initial_epoch\n",
    "#                     validation_data=(x_test, x_test),   # What goes into the loss function each epoch.\n",
    "#                     callbacks=[\n",
    "#                         model_checkpoint_callback,\n",
    "#                         tensor_board_callback,\n",
    "#                         csvlogger_callback,\n",
    "# #                     early_stopping_callback,\n",
    "#                     ])\n",
    "    \n",
    "# except KeyboardInterrupt:\n",
    "#     tf.keras.backend.clear_session()\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time-start_time\n",
    "# print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61db3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import model_from_json\n",
    "\n",
    "# json_file = open(f'Unet_{load_version}_regen.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()                                  # added lines below\n",
    "# loaded_model = model_from_json(loaded_model_json)  \n",
    "# loaded_model.summary()\n",
    "\n",
    "# import pydot\n",
    "# import pydotplus\n",
    "# tf.keras.utils.plot_model(loaded_model, show_shapes=True, show_layer_names=True)\n",
    "# # loaded_model.load_weights(f'Unet_{load_version}_regen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ddc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # from keras.models import model_from_json\n",
    "# Unet_json = loaded_model.to_json()         # save architecture\n",
    "# with open(f\"Unet_{load_version}.json\", \"w\") as json_file:\n",
    "#     json_file.write(Unet_json)\n",
    "# # serialize weights to HDF5\n",
    "# loaded_model.save_weights(f\"Unet_{load_version}.h5\")       # save weights\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43c7b0",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab2b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean_images= loaded_model.predict(x_test)\n",
    "# Difference = x_test - Clean_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Old 3 Panel testing\"\"\"\n",
    "# gain = 5\n",
    "# cbar_scale = 1/gain\n",
    "\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# # plt.imshow(x_test[0,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# # plt.imshow(Clean_images[0,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.imshow(Difference[0,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.colorbar()\n",
    "# # plt.gray()\n",
    "# plt.tight_layout()\n",
    "# # plt.title(f'{file_names[line_num]} normalized to {scale_range}, gain of {gain}') \n",
    "# # plt.savefig(f'elaradat_{line_num}_norm_resize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b2e56",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Old 3 Panel\"\"\"\n",
    "# chan = 0\n",
    "# nil0 = 0\n",
    "# gain = 4\n",
    "# diff_gain = 10\n",
    "# cbar_scale = 1/gain\n",
    "# diff_cbar_scale = 1/diff_gain\n",
    "# # inline_num = i_start_test+nil0+chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "# inline_num = 67\n",
    "# inline_num = inline_num - i_start_test\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(18, 8), gridspec_kw={'width_ratios': [1,1,1]})\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(x_test[inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.title(f'Raw Data [gain:{gain}]')\n",
    "# plt.axis('tight')\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# plt.imshow(Clean_images[inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.title(f'Denoised [gain:{gain}]')\n",
    "# plt.axis('tight')\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.imshow(Difference[inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*diff_cbar_scale, vmax=scale_range[1]*diff_cbar_scale)\n",
    "# plt.title(f'Noise Removed [gain:{diff_gain}]')\n",
    "# plt.axis('tight')\n",
    "# plt.colorbar()\n",
    "\n",
    "\n",
    "# plt.suptitle(f'Model Prediction: Inline {inline_num+i_start_test} Epoch {epoch}')\n",
    "# fig.tight_layout()\n",
    "# # plt.gray()\n",
    "\n",
    "# plt.savefig(f'elaradat_{load_version}_3panel_epoch_{epoch}.png')\n",
    "# plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc608a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"Old format compare epochs\"\"\"\n",
    "# end = 1000\n",
    "# step = 10\n",
    "# # epochs = np.arange(10,end+step, step)\n",
    "# epochs = \n",
    "# # epochs = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "# # epochs = [10,20,30,40,50,200,400,600,800,1000]\n",
    "\n",
    "# # noisy_test = 1 # always add noise to prediction images for 1.9. change this behaviour in x_tests\n",
    "\n",
    "\n",
    "# Clean_images_lists = []\n",
    "# Difference_lists = []\n",
    "\n",
    "# for i in range(len(load_versions)):\n",
    "    \n",
    "#     loaded_model = loaded_models[i]\n",
    "#     load_version = load_versions[i]\n",
    "#     Clean_images_list = []\n",
    "#     Difference_list = []\n",
    "\n",
    "#     for epoch in epochs:\n",
    "#         loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "#         Clean_images= loaded_model.predict(x_tests[i])\n",
    "#         Difference = x_tests[i] - Clean_images \n",
    "#         Clean_images_list.append(Clean_images)\n",
    "#         Difference_list.append(Difference)\n",
    "        \n",
    "#     Clean_images_lists.append(Clean_images_list)\n",
    "#     Difference_lists.append(Difference_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f982d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Non-functional attempt at calculating predictions for all models in one function. Some issue with memory if I recall correctly\"\"\"\n",
    "# # noisy_test = 1 # always add noise to prediction images for 1.9. change this behaviour in x_tests\n",
    "# def test_models(epochs):\n",
    "#     all_clean_images = []\n",
    "#     all_differences = []\n",
    "\n",
    "#     for model_idx in range(len(load_versions)):\n",
    "\n",
    "#         loaded_model = loaded_models[model_idx]\n",
    "#         load_version = load_versions[model_idx]\n",
    "#         model_clean_images = []\n",
    "#         model_differences = []\n",
    "\n",
    "#         for epoch in epochs:\n",
    "#             if epoch < 10:\n",
    "#                 epoch = '0'+str(epoch)\n",
    "#             loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "#             Clean_images= loaded_model.predict(x_tests[model_idx])\n",
    "#             Difference = x_tests[model_idx] - Clean_images \n",
    "#             model_clean_images.append(Clean_images)\n",
    "#             model_differences.append(Difference)\n",
    "\n",
    "#         model_clean_images = np.array(model_clean_images)\n",
    "#         model_differences = np.array(model_differences)\n",
    "#         all_clean_images.append(model_clean_images)\n",
    "#         all_differences.append(model_differences)\n",
    "#     return all_clean_images, all_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21144d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs_early = np.arange(1,20+1, 1)\n",
    "# all_clean_images_early, all_differences_early = test_models(epochs_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a294c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs_full = np.arange(1,211, 10)\n",
    "# all_clean_images_full, all_differences_full = test_models(epochs_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b56bd-261e-4caa-ae8d-88a0fd6f80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tests=[x_test1, x_test, x_test]\n",
    "y_tests=[y_test1, y_test, y_test]\n",
    "scale_ranges = [scale_range, scale_range, scale_range]\n",
    "descriptions = ['MSE loss, 1 channel', 'MSE loss, 4 channels', 'MAE loss, 4 channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8cf61-fb0f-4639-a6a4-e0824df53033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For swell and going on from v5.3.2. need to specify diffto AND data to predict. allows predicting y data\"\"\"\n",
    "def test_model(load_version, loaded_model, epochs, predict, diffto):\n",
    "    model_clean_images = []\n",
    "    model_differences = []\n",
    "    model_idx = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "\n",
    "    for epoch in epochs:\n",
    "        if epoch < 10:\n",
    "            epoch = '0'+str(epoch)\n",
    "        print(epoch)\n",
    "        loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "        print('weights loaded')\n",
    "        Clean_images= loaded_model.predict(x_tests[model_idx])\n",
    "        print('predicted')\n",
    "        # print(f'x_test.shape = {x_tests[model_idx].shape}, prediction.shape = {Clean_images.shape}')\n",
    "        Difference = diffto[model_idx] - Clean_images \n",
    "        model_clean_images.append(Clean_images)\n",
    "        model_differences.append(Difference)\n",
    "\n",
    "    model_clean_images = np.array(model_clean_images)\n",
    "    model_differences = np.array(model_differences)\n",
    "    print(f'{load_version} Clean images predicted')\n",
    "    return model_clean_images, model_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5b5b5-51f9-4c17-8e88-7409f800ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" For swell and going on from v5.0. need to specify diffto. allows use in both\"\"\"\n",
    "# def test_model(load_version, loaded_model, epochs, diffto):\n",
    "#     model_clean_images = []\n",
    "#     model_differences = []\n",
    "#     model_idx = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "\n",
    "#     for epoch in epochs:\n",
    "#         if epoch < 10:\n",
    "#             epoch = '0'+str(epoch)\n",
    "#         print(epoch)\n",
    "#         loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "#         print('weights loaded')\n",
    "#         Clean_images= loaded_model.predict(x_tests[model_idx])\n",
    "#         print('predicted')\n",
    "#         # print(f'x_test.shape = {x_tests[model_idx].shape}, prediction.shape = {Clean_images.shape}')\n",
    "#         Difference = diffto[model_idx] - Clean_images \n",
    "#         model_clean_images.append(Clean_images)\n",
    "#         model_differences.append(Difference)\n",
    "\n",
    "#     model_clean_images = np.array(model_clean_images)\n",
    "#     model_differences = np.array(model_differences)\n",
    "#     print(f'{load_version} Clean images predicted')\n",
    "#     return model_clean_images, model_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model(load_version, loaded_model, epochs):\n",
    "#     model_clean_images = []\n",
    "#     model_differences = []\n",
    "#     model_idx = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "\n",
    "#     for epoch in epochs:\n",
    "#         if epoch < 10:\n",
    "#             epoch = '0'+str(epoch)\n",
    "#         print(epoch)\n",
    "#         loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "#         print('weights loaded')\n",
    "#         Clean_images= loaded_model.predict(x_tests[model_idx])\n",
    "#         print('predicted')\n",
    "#         # print(f'x_test.shape = {x_tests[model_idx].shape}, prediction.shape = {Clean_images.shape}')\n",
    "#         Difference = x_tests[model_idx] - Clean_images \n",
    "#         model_clean_images.append(Clean_images)\n",
    "#         model_differences.append(Difference)\n",
    "\n",
    "#     model_clean_images = np.array(model_clean_images)\n",
    "#     model_differences = np.array(model_differences)\n",
    "#     print(f'{load_version} Clean images predicted')\n",
    "#     return model_clean_images, model_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shrink x_test to 1 image\n",
    "# img_idx = 6\n",
    "# x_test1 = x_test[img_idx,:,:,0]\n",
    "# x_test1 = np.expand_dims(x_test1,0)\n",
    "# x_test1 = np.expand_dims(x_test1,3)\n",
    "# print(x_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_raw = 0\n",
    "epoch_choice = 1\n",
    "\n",
    "if denoise_raw:          # to test trained NN using raw data (y_test) as input\n",
    "    predict = y_tests\n",
    "elif denoise_raw == False:\n",
    "    predict = x_tests\n",
    "    \n",
    "diffto = y_tests    # the y in training is always the raw dataset for our purposes\n",
    "\n",
    "if epoch_choice == 0:\n",
    "    epochs = np.arange(1, 51, 1)\n",
    "    epochs_tag = '1_51_1'\n",
    "elif epoch_choice == 1:\n",
    "    epochs = np.arange(10, 1001, 10)\n",
    "    epochs_tag = '10_1001_10'\n",
    "\n",
    "### epochs = np.arange(0, 50, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84558c9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Predict and save\"\"\"\n",
    "import pickle\n",
    "\n",
    "for i in range(len(load_versions)):\n",
    "    load_version = load_versions[i]\n",
    "    loaded_model = load_model(load_version) \n",
    "    # epochs = np.arange(1, 200, 10)\n",
    "    # print(x_tests[i].shape)\n",
    "    model_clean_images, model_differences = test_model(load_version, loaded_model, epochs, predict, diffto)\n",
    "    # print(model_clean_images.shape)\n",
    "    if denoise_raw == False:\n",
    "        with open(f'./Predictions/clean_images_{load_version}_{epochs_tag}.pkl', 'wb') as file:\n",
    "             pickle.dump(model_clean_images,file)\n",
    "        with open(f'./Predictions/differences_{load_version}_{epochs_tag}.pkl', 'wb') as file:\n",
    "             pickle.dump(model_differences,file)\n",
    "    elif denoise_raw == True:\n",
    "        with open(f'./Predictions/clean_images_{load_version}_{epochs_tag}_ypred.pkl', 'wb') as file:\n",
    "             pickle.dump(model_clean_images,file)\n",
    "        with open(f'./Predictions/differences_{load_version}_{epochs_tag}_ypred.pkl', 'wb') as file:\n",
    "             pickle.dump(model_differences,file)\n",
    "    print(f'{load_version} Predictions pickled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load predictions\"\"\"\n",
    "import pickle\n",
    "\n",
    "all_clean_images, all_differences = [], []\n",
    "for load_version in load_versions:\n",
    "    if denoise_raw == False:\n",
    "        with open(f'./Predictions/clean_images_{load_version}_{epochs_tag}.pkl', 'rb') as file:\n",
    "            model_clean_images = pickle.load(file)\n",
    "    elif denoise_raw == True:\n",
    "        with open(f'./Predictions/differences_{load_version}_{epochs_tag}_ypred.pkl', 'rb') as file:\n",
    "            model_differences = pickle.load(file)\n",
    "\n",
    "    all_clean_images.append(model_clean_images)\n",
    "    all_differences.append(model_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc9152-71f6-40bc-9fec-8e520f1196e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_clean_images:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c389b22",
   "metadata": {},
   "source": [
    "#### Gif stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad0457",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"Non-functional? Create several gifs\"\"\"\n",
    "# test_idx = 0\n",
    "# gain = 15\n",
    "# framerate = 10\n",
    "# tag = 'full_diff'\n",
    "\n",
    "# from array2gif import write_gif\n",
    "# import time\n",
    "\n",
    "# epochs_full = np.arange(1,201, 1)\n",
    "\n",
    "# for model_idx in range(len(load_versions)):\n",
    "   \n",
    "#     loaded_model = loaded_models[model_idx]\n",
    "#     load_version = load_versions[model_idx]\n",
    "#     model_clean_images = []\n",
    "#     model_differences = []\n",
    "\n",
    "#     for epoch in epochs:\n",
    "#         if epoch < 10:\n",
    "#             epoch = '0'+str(epoch)\n",
    "#         loaded_model.load_weights(f'./Logs/checkpoints_{load_version}/ckpt-{epoch}.hdf5')\n",
    "#         Clean_images= loaded_model.predict(x_tests[model_idx])\n",
    "#         Difference = x_tests[model_idx] - Clean_images \n",
    "#         model_clean_images.append(Clean_images)\n",
    "#         model_differences.append(Difference)\n",
    "\n",
    "#     model_clean_images = np.array(model_clean_images)\n",
    "#     model_differences = np.array(model_differences)\n",
    "    \n",
    "#     scale_range = scale_ranges[model_idx]\n",
    "#     model_differences = model_differences.transpose(0,2,3,1,4).reshape((model_differences.shape[0],data.shape[1],data.shape[2],  # collect all channels of the test data (since each channel is actually a standalone image)\n",
    "#                                                      model_differences.shape[1]*model_differences.shape[4]), order='C')\n",
    "#     gain_0 = -127.5*gain+127.5     # expands 0-255 range. values outside 0-255 will later be clipped\n",
    "#     gain_255 = 127.5*gain+127.5\n",
    "#     images_array_rgb = gain_0+((model_differences-scale_range[0])*(gain_255-gain_0))/(scale_range[1] - scale_range[0])   # minmax scale to fit 0,255 range. clip to that range. Gain implementation goes here\n",
    "#     images_array_rgb = np.clip(images_array_rgb,0,255)   # I think to use gain, just widen the 0,255 range above. it will clip just like a display\n",
    "#     images_array_rgb = np.tile(np.expand_dims(images_array_rgb, 1),(1,3,1,1,1)) # insert a dimension after the number of epochs. Duplicate the images twice over this axis to get fake rgb images\n",
    "#     images_array_rgb = images_array_rgb.astype(int)\n",
    "#     # images_array_rgb = np.split(images_array_rgb, images_array.shape[0], 0) # converts to list of arrays for compat with array2gif\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     load_version = load_versions[model_idx]\n",
    "\n",
    "#     images_array_rgb = images_array_rgb.transpose(0,1,3,2,4)\n",
    "#     write_gif(images_array_rgb[:,:,:,:,test_idx],f'Unet_{load_version}_il{nil0+idx_end+test_idx}_{tag}.gif',fps=framerate)\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print(f'{load_version} saved, Elapsed time: {elapsed_time}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99160f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepgif(all_list, model_idx, gain):\n",
    "    images_array = all_list[model_idx]\n",
    "    scale_range = scale_ranges[model_idx]\n",
    "    images_array = images_array.transpose(0,2,3,1,4).reshape((images_array.shape[0],data.shape[1],data.shape[2],  # collect all channels of the test data (since each channel is actually a standalone image)\n",
    "                                                     images_array.shape[1]*images_array.shape[4]), order='C')\n",
    "    gain_0 = -127.5*gain+127.5     # expands 0-255 range. values outside 0-255 will later be clipped\n",
    "    gain_255 = 127.5*gain+127.5\n",
    "    images_array_0_255 = gain_0+((images_array-scale_range[0])*(gain_255-gain_0))/(scale_range[1] - scale_range[0])   # minmax scale to fit 0,255 range. clip to that range. Gain implementation goes here\n",
    "    images_array_0_255 = np.clip(images_array_0_255,0,255)   # I think to use gain, just widen the 0,255 range above. it will clip just like a display\n",
    "    images_array_rgb = np.tile(np.expand_dims(images_array_0_255, 1),(1,3,1,1,1)) # insert a dimension after the number of epochs. Duplicate the images twice over this axis to get fake rgb images\n",
    "    images_array_rgb = images_array_rgb.astype(int)\n",
    "    # images_array_rgb = np.split(images_array_rgb, images_array.shape[0], 0) # converts to list of arrays for compat with array2gif\n",
    "    return images_array_rgb, images_array\n",
    "\n",
    "from array2gif import write_gif\n",
    "import time\n",
    "\n",
    "def writegif(all_list, model_idx, test_idx, gain, framerate, epochs_tag, type_tag):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    load_version = load_versions[model_idx]\n",
    "    model_differences_rgb, _ = prepgif(all_list, model_idx, gain)\n",
    "    model_differences_rgb = model_differences_rgb.transpose(0,1,3,2,4)\n",
    "    # write_gif(model_differences_rgb[:,:,:,:,test_idx],f'Unet_{load_version}_il{nil0+idx_end+test_idx}_{tag}.gif',fps=framerate) # This was for when multiple images were predicted\n",
    "    write_gif(model_differences_rgb[:,:,:,:,test_idx],f'Unet_{load_version}_{epochs_tag}_{type_tag}.gif',fps=framerate)\n",
    "\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{load_version} saved, Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60c335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f980c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_list = all_differences\n",
    "test_idx = 0\n",
    "# gain = 15\n",
    "framerate = 5\n",
    "epochs_tag = epochs_tag\n",
    "type_tag = 'Diff'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, epochs_tag, type_tag)\n",
    "# writegif(all_list, 1, test_idx, gain, framerate, tag)\n",
    "# writegif(all_list, 2, test_idx, gain, framerate, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af259879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_list = all_clean_images\n",
    "type_tag = 'Clean'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, epochs_tag, type_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419411a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = 0\n",
    "# chan = 0\n",
    "# Clean_images_list = Clean_images_lists[model]\n",
    "# Clean_images_array = np.array(Clean_images_lists[model])\n",
    "# scale_range = scale_ranges[i]\n",
    "# # Clean_images_array = Clean_images_list[\n",
    "# Clean_images_array = Clean_images_array.transpose(0,2,3,1,4).reshape((len(epochs),data.shape[1],data.shape[2],  # collect all channels of the test data (since each channel is actually a standalone image)\n",
    "#                                                  Clean_images_array.shape[1]*Clean_images_array.shape[4]), order='C')\n",
    "# Clean_images_array_0_255 = 0+((Clean_images_array-scale_range[0])*(255-0))/(scale_range[1] - scale_range[0])   # minmax scale to fit 0,255 range. clip to that range. Gain implementation goes here\n",
    "# Clean_images_array_0_255 = np.clip(Clean_images_array_0_255,0,255)   # I think to use gain, just widen the 0,255 range above. it will clip just like a display\n",
    "# Clean_images_array_rgb = np.tile(np.expand_dims(Clean_images_array_0_255, 1),(1,3,1,1,1)) # insert a dimension after the number of epochs. Duplicate the images twice over this axis to get fake rgb images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fb0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_list = all_differences_early\n",
    "test_idx = 0\n",
    "gain = 1\n",
    "framerate = 2\n",
    "tag = 'early_diff'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 1, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 2, test_idx, gain, framerate, tag)\n",
    "# writegif(all_list, 3, test_idx, gain, framerate, tag)\n",
    "\n",
    "all_list = all_clean_images_early\n",
    "test_idx = 0\n",
    "gain = 1\n",
    "framerate = 2\n",
    "tag = 'early_clean'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 1, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 2, test_idx, gain, framerate, tag)\n",
    "# writegif(all_list, 3, test_idx, gain, framerate, tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc79874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_list = all_differences_full\n",
    "test_idx = 0\n",
    "gain = 15\n",
    "framerate = 10\n",
    "tag = 'full_diff'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 1, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 2, test_idx, gain, framerate, tag)\n",
    "# writegif(all_list, 3, test_idx, gain, framerate, tag)\n",
    "\n",
    "all_list = all_clean_images_full\n",
    "test_idx = 0\n",
    "gain = 1\n",
    "framerate = 10\n",
    "tag = 'full_clean'\n",
    "writegif(all_list, 0, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 1, test_idx, gain, framerate, tag)\n",
    "writegif(all_list, 2, test_idx, gain, framerate, tag)\n",
    "# writegif(all_list, 3, test_idx, gain, framerate, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efa536",
   "metadata": {},
   "source": [
    "#### Not gif stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa5305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = np.fft.fft2(all_clean_images[0][19,0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c006701",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#axes format not working. Next cell tries plt.plot\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "chan = 1\n",
    "# nil0 = 0\n",
    "gain = 1\n",
    "diff_gain = 10\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_idx = idx_end + chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "# inline_num = idx_end + nil0\n",
    "# inline_num = inline_num - i_start_test\n",
    "inline_idx = 0\n",
    "\n",
    "i = 0\n",
    "Clean_images_list = Clean_images_lists[i]\n",
    "scale_range = scale_ranges[i]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "axes = axes.flatten()\n",
    "\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    axes[i].imshow(Clean_images_list[i][inline_idx,:,:,chan].T,\n",
    "                   # cmap='RdYlBu', \n",
    "                   vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "    axes[i].colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ad7ab",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#axes format not working. This cell uses plt.plot\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "chan = 1\n",
    "# nil0 = 0\n",
    "gain = 1\n",
    "diff_gain = 10\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_idx = idx_end + chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "# inline_num = idx_end + nil0\n",
    "# inline_num = inline_num - i_start_test\n",
    "inline_idx = 0\n",
    "\n",
    "\n",
    "i = 3 #         Manually select model\n",
    "print(load_versions[i])\n",
    "Clean_images_list = Clean_images_lists[i]\n",
    "scale_range = scale_ranges[i]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "axes = axes.flatten()\n",
    "\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(Clean_images_list[i][inline_idx,:,:,chan].T,\n",
    "               # cmap='RdYlBu', \n",
    "               vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale\n",
    "              )\n",
    "    plt.colorbar()\n",
    "    plt.axis('tight')\n",
    "    plt.title(epochs[i])\n",
    "# plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('test')\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1e22b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#axes format not working. Next cell tries plt.plot\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "chan = 1\n",
    "# nil0 = 0\n",
    "gain = 1\n",
    "diff_gain = 15\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_idx = idx_end + chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "# inline_num = idx_end + nil0\n",
    "# inline_num = inline_num - i_start_test\n",
    "inline_idx = 0\n",
    "\n",
    "\n",
    "i = 0#         Manually select model\n",
    "print(load_versions[i])\n",
    "Difference_list = Difference_lists[i]\n",
    "scale_range = scale_ranges[i]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "axes = axes.flatten()\n",
    "\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(Difference_list[i][inline_idx,:,:,chan].T,\n",
    "               # cmap='RdYlBu', \n",
    "               vmin=scale_range[0]*diff_cbar_scale, vmax=scale_range[1]*diff_cbar_scale\n",
    "              )\n",
    "    plt.colorbar()\n",
    "    plt.axis('tight')\n",
    "    plt.title(epochs[i])\n",
    "# plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('test')\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5194681-9386-4fc5-a204-9822876caa9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image = images[0][0,:,:,chan].T\n",
    "image = output_data[idx_end, :, :, chan] # want to keep timeseries as rows for fft, don't transpose\n",
    "ps = np.average(np.abs(np.fft.fft(image)), axis=0)\n",
    "freqs = np.fft.fftfreq(ps.size, 2*10**-3)\n",
    "idx = np.argsort(freqs)\n",
    "idx = idx[len(idx)//2:]\n",
    "plt.plot(freqs[idx], ps[idx])\n",
    "plt.title('output image power spectrum (assumed sampling)')\n",
    "plt.show()\n",
    "\n",
    "# freqs = np.fft.fftfreq("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166497e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" updated 2.4.2\"\"\"\n",
    "\n",
    "# # from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# chan = 0\n",
    "# # nil0 = 0\n",
    "# gain = 0.2\n",
    "# diff_gain = 10\n",
    "# cbar_scale = 1/gain\n",
    "# diff_cbar_scale = 1/diff_gain\n",
    "# # inline_idx = idx_end + chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "# # inline_num = idx_end + nil0\n",
    "# # inline_num = inline_num - i_start_test\n",
    "# inline_idx = 0\n",
    "\n",
    "\n",
    "# model_idx = 0\n",
    "# load_version = load_versions[model_idx] #         Manually select model\n",
    "# description = descriptions[model_idx]\n",
    "# # i = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "# print(load_versions[model_idx])\n",
    "# print(descriptions[model_idx])\n",
    "# model_clean_images = all_clean_images[model_idx]\n",
    "# model_differences = all_differences[model_idx]\n",
    "# scale_range = scale_ranges[model_idx]\n",
    "\n",
    "# # fig = plt.subplots(figsize=(3.6, 7.2))\n",
    "# # plt.imshow(y_tests[i][inline_idx,:,:,chan].T, vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale, aspect='auto')\n",
    "# # plt.title(f'Line {idx_end+nil0+inline_idx}')\n",
    "# # plt.axis('tight')\n",
    "# # plt.gray()\n",
    "# # # plt.savefig(f'elaradat_il{idx_end+nil0+inline_idx}_gain{gain}.png')\n",
    "# # plt.savefig(f'swelldat_il{idx_end+nil0+inline_idx}_output_gain{gain}.png')\n",
    "\n",
    "# fig, axes = plt.subplots(2, 5, figsize=(18, 9),\n",
    "#                        # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "#                       )\n",
    "# axes = axes.flatten()\n",
    "\n",
    "\n",
    "# if type_tag == 'Clean':\n",
    "#     images = model_clean_images\n",
    "#     # [9:109:10] \n",
    "# if type_tag == 'Diff':\n",
    "#     images = model_differences\n",
    "#     # [9:109:10]    # Change based on epochs to select\n",
    "# # gain = diff_gain\n",
    "\n",
    "# # plt.rc('font', size=16)\n",
    "\n",
    "# range_ends = [0,9]\n",
    "# plotnum = 1\n",
    "# for i in range(range_ends[0],range_ends[1]+1):\n",
    "\n",
    "#     plt.subplot(2,5,plotnum)\n",
    "#     plt.imshow(images[i][inline_idx,:,:,chan].T,\n",
    "#                # cmap='RdYlBu', \n",
    "#                vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale\n",
    "#               )\n",
    "#     plt.gray()\n",
    "#     plt.colorbar()\n",
    "#     plt.axis('tight')\n",
    "#     # plt.title(epochs[9:109:10][i])\n",
    "#     plt.title(epochs[i])\n",
    "#     plotnum+=1\n",
    "# # plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "# # plt.suptitle(f'Mo DeepRift {type_tag} Line {idx_end+nil0+inline_idx}, gain: {gain}\\n{load_version}: {description}', y=1)\n",
    "# plt.suptitle(f'Swell {type_tag} Line {idx_end+nil0+inline_idx}, gain: {gain}\\n{load_version}: {description}', y=1)\n",
    "\n",
    "\n",
    "# fig.tight_layout()\n",
    "# # plt.savefig(f'Unet_{load_version}_il{idx_end+nil0+inline_idx}_gain{gain}_img{range_ends[0]}_{range_ends[1]}.png')\n",
    "# plt.savefig(f'Unet_{load_version}_il{idx_end+nil0+inline_idx}_predict_gain{gain}_{type_tag}.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7e8a-fa99-4174-b7a6-842e98afa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d836d-17a3-48b5-b2dd-b8a7b75cc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = output_data[137,:,:,chan]\n",
    "fftshift = np.fft.fftshift(image)\n",
    "fft2 = np.fft.fft2(image)\n",
    "fft2shift = np.fft.ifftshift(fft2)\n",
    "plt.imshow((np.abs(fft2shift)),\n",
    "           origin = 'lower', \n",
    "           cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f11c5-bb5b-4455-8131-3d40197121e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = output_data[137,:,:,chan]\n",
    "# fftshift = np.fft.fftshift(image)\n",
    "fft1 = np.fft.fft(image, axis=0)\n",
    "fft2 = np.fft.fft(fft1, axis=1)\n",
    "fft2shift = np.fft.ifft(fft2) # swaps all half spaces\n",
    "plt.imshow(10*np.log10(np.abs(fft2shift)).T, origin = 'lower', cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f97b0-d745-4c6f-aed0-2cd2bfdc7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.fft.fft(image, axis=0)\n",
    "test = np.fft.fft(test, axis=1)\n",
    "plt.imshow(abs(test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51029659-9e0d-4aa5-b842-d62a1bd4d94c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" updated 5.*\"\"\"\n",
    "plot_pred = 0\n",
    "plot_ps = 1\n",
    "plot_fk = 0\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# model_idx = 1\n",
    "# type_tag = 'Clean'\n",
    "# epoch_selection = 0\n",
    "# gain = 0.2 # 0.2\n",
    "\n",
    "sample_interval = 2*10**-3\n",
    "        \n",
    "idx_end = 137\n",
    "inline_idx = 0\n",
    "chan = 0\n",
    "# nil0 = 0\n",
    "\n",
    "\n",
    "for model_idx in [0,1,2]:\n",
    "    for type_tag in ['Clean', 'Diff']:\n",
    "        for gain in [5, 1]:\n",
    "            for epoch_selection in [0,1]:\n",
    "                if epochs_tag == '10_1001_10':\n",
    "                    if epoch_selection == 0:\n",
    "                        epoch_plot_tag = '10-100'\n",
    "                    elif epoch_selection == 1:\n",
    "                        epoch_plot_tag = '100-1000' \n",
    "                elif epochs_tag == '1_51_1':\n",
    "                    if epoch_selection == 0: # no second option for the ealy epochs\n",
    "                         epoch_plot_tag = '1-10'\n",
    "                    elif epoch_selection == 1:\n",
    "                        break\n",
    "                        \n",
    "                diff_gain = 10\n",
    "                cbar_scale = 1/gain\n",
    "                diff_cbar_scale = 1/diff_gain\n",
    "\n",
    "                load_version = load_versions[model_idx] #         \n",
    "                description = descriptions[model_idx]\n",
    "                # i = np.where(np.array(load_versions)==load_version)[0][0]\n",
    "                print(load_versions[model_idx])\n",
    "                print(descriptions[model_idx])\n",
    "                model_clean_images = all_clean_images[model_idx]\n",
    "                model_differences = all_differences[model_idx]\n",
    "                scale_range = scale_ranges[model_idx]\n",
    "                \n",
    "                fig_name = f'./Predictions/Unet_{load_version}_il{idx_end+nil0+inline_idx}_gain{gain}_predict_{epoch_plot_tag}_{type_tag}.png'\n",
    "                print(fig_name)\n",
    "\n",
    "                # fig = plt.subplots(figsize=(3.6, 7.2))\n",
    "                # plt.imshow(y_tests[i][inline_idx,:,:,chan].T, vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale, aspect='auto')\n",
    "                # plt.title(f'Line {idx_end+nil0+inline_idx}')\n",
    "                # plt.axis('tight')\n",
    "                # plt.gray()\n",
    "                # # plt.savefig(f'elaradat_il{idx_end+nil0+inline_idx}_gain{gain}.png')\n",
    "                # plt.savefig(f'swelldat_il{idx_end+nil0+inline_idx}_output_gain{gain}.png')\n",
    "\n",
    "                                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "\n",
    "                if type_tag == 'Clean':\n",
    "                    if epoch_selection == 0:\n",
    "                        images = model_clean_images\n",
    "                        epoch_titles = epochs\n",
    "                    elif epoch_selection == 1:\n",
    "                        images = model_clean_images[9:109:10] \n",
    "                        epoch_titles = epochs[9:109:10] \n",
    "                if type_tag == 'Diff':\n",
    "                    if epoch_selection == 0:\n",
    "                        images = model_differences\n",
    "                        epoch_titles = epochs\n",
    "                    elif epoch_selection == 1:\n",
    "                        images = model_differences[9:109:10] \n",
    "                        epoch_titles = epochs[9:109:10] \n",
    "                    # [9:109:10]    # Change based on epochs to select\n",
    "                # gain = diff_gain\n",
    "\n",
    "                # plt.rc('font', size=16)\n",
    "                print(images.shape)\n",
    "                \n",
    "                if plot_pred:\n",
    "                    fig, axes = plt.subplots(2, 5, figsize=(18, 9))\n",
    "                    axes = axes.flatten()\n",
    "\n",
    "                    range_ends = [0,9]\n",
    "                    plotnum = 1\n",
    "                    for i in range(range_ends[0],range_ends[1]+1):\n",
    "\n",
    "                        plt.subplot(2,5,plotnum)\n",
    "                        plt.imshow(images[i][inline_idx,:,:,chan].T,\n",
    "                                   # cmap='RdYlBu', \n",
    "                                   vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale\n",
    "                                  )\n",
    "                        plt.gray()\n",
    "                        plt.colorbar()\n",
    "                        plt.axis('tight')\n",
    "                        # plt.title(epochs[9:109:10][i])\n",
    "                        plt.title(epoch_titles[i])\n",
    "                        plotnum+=1\n",
    "                    # plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "                    # plt.suptitle(f'Mo DeepRift {type_tag} Line {idx_end+nil0+inline_idx}, gain: {gain}\\n{load_version}: {description}', y=1)\n",
    "                    plt.suptitle(f'Swell {type_tag}\\n{load_version}\\n{description}\\ngain: {gain}', y=1)\n",
    "                    fig.tight_layout()\n",
    "                    # plt.savefig(f'Unet_{load_version}_il{idx_end+nil0+inline_idx}_gain{gain}_img{range_ends[0]}_{range_ends[1]}.png')\n",
    "                    plt.savefig(fig_name)\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "                \n",
    "                if gain ==1:\n",
    "                    \"\"\" Power Spectra \"\"\"\n",
    "#                     if plot_ps:\n",
    "#                         fig, axes = plt.subplots(2, 5, figsize=(18, 9))\n",
    "#                         axes = axes.flatten()\n",
    "\n",
    "#                         range_ends = [0,9]\n",
    "#                         plotnum = 1\n",
    "#                         for i in range(range_ends[0],range_ends[1]+1):\n",
    "#                             plt.subplot(2,5,plotnum)\n",
    "#                             image = images[i][inline_idx,:,:,chan]\n",
    "#                             ps = np.average(np.abs(np.fft.fft(image)), axis=0)\n",
    "#                             freqs = np.fft.fftfreq(ps.size, sample_interval)\n",
    "#                             idx = np.argsort(freqs)\n",
    "#                             idx = idx[len(idx)//2:]\n",
    "#                             plt.plot(freqs[idx], ps[idx])\n",
    "#                             plt.axis('tight')\n",
    "#                             plt.xlim([0,50])\n",
    "#                             # plt.title(epochs[9:109:10][i])\n",
    "#                             plt.title(epoch_titles[i])\n",
    "#                             plotnum+=1\n",
    "#                         # plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "#                         # plt.suptitle(f'Mo DeepRift {type_tag} Line {idx_end+nil0+inline_idx}, gain: {gain}\\n{load_version}: {description}', y=1)\n",
    "#                         plt.suptitle(f'Swell {type_tag} Power Spectra\\n{load_version}\\n{description}', y=1)\n",
    "\n",
    "#                         fig.tight_layout()\n",
    "#                         # plt.savefig(f'Unet_{load_version}_il{idx_end+nil0+inline_idx}_gain{gain}_img{range_ends[0]}_{range_ends[1]}.png')\n",
    "#                         ps_fig_name = f'./Predictions/Unet_{load_version}_il{idx_end+nil0+inline_idx}_predict_{epoch_plot_tag}_{type_tag}_ps.png'\n",
    "#                         # plt.savefig(ps_fig_name)\n",
    "#                         plt.show()\n",
    "\n",
    "#                         plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "                    \"\"\" FK Spectra \"\"\"\n",
    "                    if plot_fk:\n",
    "                        fig, axes = plt.subplots(2, 5, figsize=(18, 9))\n",
    "                        axes = axes.flatten()\n",
    "\n",
    "                        range_ends = [0,9]\n",
    "                        plotnum = 1\n",
    "                        for i in range(range_ends[0],range_ends[1]+1):\n",
    "                            plt.subplot(2,5,plotnum)\n",
    "                            image = images[i][inline_idx,:,:,chan]\n",
    "                            plt.imshow(np.abs(np.fft.fft2(image)).T)\n",
    "                            plt.title(epoch_titles[i])\n",
    "                            plotnum+=1\n",
    "                        # plt.suptitle(f'{load_versions[i]}')\n",
    "\n",
    "                        # plt.suptitle(f'Mo DeepRift {type_tag} Line {idx_end+nil0+inline_idx}, gain: {gain}\\n{load_version}: {description}', y=1)\n",
    "                        plt.suptitle(f'Swell {type_tag} FK\\n{load_version}\\n{description}', y=1)\n",
    "\n",
    "                        fig.tight_layout()\n",
    "                        # plt.savefig(f'Unet_{load_version}_il{idx_end+nil0+inline_idx}_gain{gain}_img{range_ends[0]}_{range_ends[1]}.png')\n",
    "                        ps_fig_name = f'./Predictions/Unet_{load_version}_il{idx_end+nil0+inline_idx}_predict_{epoch_plot_tag}_{type_tag}_fk.png'\n",
    "                        plt.savefig(ps_fig_name)\n",
    "                        plt.show()\n",
    "\n",
    "                        plt.rcParams.update(plt.rcParamsDefault)\n",
    "            \n",
    "                else:\n",
    "                    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67a01f-80b7-4811-9792-78f5a862f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_epochs_slice = slice(4,109,5)\n",
    "# ps_epochs_slice = slice(0,109,1)\n",
    "epochs[ps_epochs_slice]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4c328-2336-43c0-ae90-f3cabf92fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean_images[:,inline_idx,:,:,chan].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d9664-a3e7-49b8-ae6d-b224b31e7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Power Spectra \"\"\"             \"\"\"DO I NEED TO MULTIPLY FFT BY DT??????\"\"\"\n",
    "ps_epochs_slice\n",
    "inline_idx = 0\n",
    "chan=0\n",
    "sample_interval = 1/1000\n",
    "dB_bool = True\n",
    "type_tag = 'Diff'\n",
    "detrend_mean = 1\n",
    "\n",
    "\n",
    "epochs_cmap = plt.cm.plasma(np.linspace(0,1,len(epochs[ps_epochs_slice])))\n",
    "\n",
    "nrows = 1\n",
    "\n",
    "fig, axes = plt.subplots(nrows, len(load_versions), figsize=(4*len(load_versions), 8*nrows))\n",
    "axes = axes.flatten()\n",
    "for model_idx in range(len(load_versions)):\n",
    "    \n",
    "    load_version = load_versions[model_idx] #         \n",
    "    description = descriptions[model_idx]\n",
    "    model_clean_images = all_clean_images[model_idx]\n",
    "    model_differences = all_differences[model_idx]\n",
    "    scale_range = scale_ranges[model_idx]\n",
    "    \n",
    "    \"\"\"plot power spectrum for epoch\"\"\"\n",
    "    plt.subplot(2,3,model_idx+1)\n",
    "    if type_tag == 'Clean':\n",
    "        images = model_clean_images[ps_epochs_slice][:,inline_idx,:,:,chan]\n",
    "    elif type_tag == 'Diff':\n",
    "        images = model_differences[ps_epochs_slice][:,inline_idx,:,:,chan]\n",
    "    if detrend_mean:\n",
    "        img_avgs = np.mean(images, axis=(1,2))\n",
    "        for epoch_idx in range(len(images)):\n",
    "            images[epoch_idx] = images[epoch_idx] - img_avgs[epoch_idx]\n",
    "\n",
    "    for epoch_idx in range(images.shape[0]):\n",
    "        image = images[epoch_idx,:,:]\n",
    "        ps = np.average(np.abs(np.fft.fft(image)), axis=0)\n",
    "        freqs = np.fft.fftfreq(ps.size, sample_interval)\n",
    "        idx = np.argsort(freqs)\n",
    "        idx = idx[len(idx)//2:]\n",
    "        if epoch_idx == 0 or epoch_idx == images.shape[0]-1:      # just put ends of color gradient on legend\n",
    "            condlabel = f'Epoch {epochs[ps_epochs_slice][epoch_idx]}'\n",
    "        else:\n",
    "            condlabel = None\n",
    "        if dB_bool == True:\n",
    "            plt.plot(freqs[idx], 20*np.log10(ps[idx]), color = epochs_cmap[epoch_idx], label = condlabel)\n",
    "            plt.ylabel('dB')\n",
    "            power_amp_tag = 'Power'\n",
    "        else:\n",
    "            plt.plot(freqs[idx], ps[idx], color = epochs_cmap[epoch_idx], label = condlabel)\n",
    "            plt.ylabel('Amplitude')\n",
    "            power_amp_tag = 'Amplitude'\n",
    "        plt.xlabel('Hz *need to fix with dt')\n",
    "        plt.axis('tight')\n",
    "        # plt.xlim([0,50])\n",
    "        plt.title(f'{description}')\n",
    "        # plt.suptitle(f'{load_versions[i]}')\n",
    "        \n",
    "    \"\"\"plot input/output power spectra\"\"\"\n",
    "    input_image = x_test[inline_idx, :, :, chan]\n",
    "    output_image = y_test[inline_idx, :, :, chan]\n",
    "    diff_image = output_image-input_image\n",
    "    input_ps = np.average(np.abs(np.fft.fft(input_image)), axis=0)\n",
    "    output_ps = np.average(np.abs(np.fft.fft(output_image)), axis=0)\n",
    "    diff_ps = np.average(np.abs(np.fft.fft(diff_image)), axis=0)\n",
    "    if dB_bool == True and type_tag == 'Clean':\n",
    "        plt.plot(freqs[idx], 20*np.log10(input_ps[idx]), color = 'darkblue', linestyle = 'dotted', label = 'Input Image')\n",
    "        plt.plot(freqs[idx], 20*np.log10(output_ps[idx]), color = 'darkred', linestyle = 'dotted', label = 'Output Image')\n",
    "    elif dB_bool == False and type_tag == 'Clean':\n",
    "        plt.plot(freqs[idx], input_ps[idx], color = 'darkblue', linestyle = 'dotted', label = 'Input Image')\n",
    "        plt.plot(freqs[idx], output_ps[idx], color = 'darkred', linestyle = 'dotted', label = 'Output Image')\n",
    "    elif dB_bool == True and type_tag == 'Diff':\n",
    "        plt.plot(freqs[idx], 20*np.log10(input_ps[idx]), color = 'darkblue', linestyle = 'dotted', label = 'Input Image')\n",
    "        plt.plot(freqs[idx], 20*np.log10(output_ps[idx]), color = 'darkred', linestyle = 'dotted', label = 'Output Image')\n",
    "        plt.plot(freqs[idx], 20*np.log10(diff_ps[idx]), color = 'grey', linestyle = 'dotted', label = 'True difference')\n",
    "    elif dB_bool == False and type_tag == 'Diff':\n",
    "        plt.plot(freqs[idx], input_ps[idx], color = 'darkblue', linestyle = 'dotted', label = 'Input Image')\n",
    "        plt.plot(freqs[idx], output_ps[idx], color = 'darkred', linestyle = 'dotted', label = 'Output Image')\n",
    "        plt.plot(freqs[idx], diff_ps[idx], color = 'grey', linestyle = 'dotted', label = 'True difference')    \n",
    "    plt.legend(loc='lower center')\n",
    "    plt.suptitle(f'Swell {type_tag} Image {power_amp_tag} Spectra', y=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "# ps_fig_name = f'./Predictions/Unet_{load_version}_il{idx_end+nil0+inline_idx}_predict_{epoch_plot_tag}_{type_tag}_ps.png'\n",
    "# plt.savefig(ps_fig_name)\n",
    "plt.show()\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f09ec4-83ed-4b1d-a52b-87eac1b63211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7280bb8-5356-4f18-9abd-1841ef786d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_differences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33146c4-b519-4ecb-aaac-82c69d6b84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = images[0][0,:,:,chan].T\n",
    "\n",
    "input_image = x_test[inline_idx, :, :, chan]\n",
    "output_image = y_test[inline_idx, :, :, chan]\n",
    "diff_image = output_image - input_image\n",
    "input_ps = np.average(np.abs(np.fft.fft(input_image)), axis=0)\n",
    "output_ps = np.average(np.abs(np.fft.fft(output_image)), axis=0)\n",
    "diff_ps = np.average(np.abs(np.fft.fft(diff_image)), axis=0)\n",
    "plt.plot(freqs[idx], input_ps[idx])\n",
    "plt.plot(freqs[idx], output_ps[idx])\n",
    "plt.plot(freqs[idx], diff_ps[idx])\n",
    "plt.yscale('log')\n",
    "plt.title('output image power spectrum (assumed sampling)')\n",
    "plt.show()\n",
    "\n",
    "# freqs = np.fft.fftfreq("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4417299",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_num = 3 # line to view\n",
    "gain = 5\n",
    "cbar_scale = 1/gain\n",
    "scale_range = scale_ranges[0]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(x_test[line_num,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "plt.colorbar()\n",
    "plt.gray()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(all_clean_images[2][19,line_num,:,:,0].T, aspect='auto', cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "# plt.colorbar()\n",
    "# plt.gray()\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99319fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152a02a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chan = 0\n",
    "nil0 = 0\n",
    "gain = 4\n",
    "diff_gain = 10\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_num = i_start_test+nil0+chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "inline_num = 67\n",
    "inline_num = inline_num - i_start_test\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    ax[i].imshow(Clean_images_list[i][inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "    ax[i].colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b77605",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "chan = 0\n",
    "nil0 = 0\n",
    "gain = 4\n",
    "diff_gain = 10\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_num = i_start_test+nil0+chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "inline_num = 67\n",
    "inline_num = inline_num - i_start_test\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    im = ax[i].imshow(Clean_images_list[i][inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "    divider = make_axes_locatable(ax[i])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    plt.axis('tight')\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2cb1c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(Clean_images_list[6][inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "plt.colorbar()\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce85cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_images_list[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39fd17",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "chan = 0\n",
    "nil0 = 0\n",
    "gain = 4\n",
    "diff_gain = 10\n",
    "cbar_scale = 1/gain\n",
    "diff_cbar_scale = 1/diff_gain\n",
    "# inline_num = i_start_test+nil0+chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "inline_num = 67\n",
    "inline_num = inline_num - i_start_test\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(18, 9),\n",
    "                       # gridspec_kw={'width_ratios': np.ones((3,3))}\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "\n",
    "# plt.rc('font', size=16)\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    print(i)\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Clean_images_list[i][inline_num,:,:,chan].T, cmap='RdYlBu', vmin=scale_range[0]*cbar_scale, vmax=scale_range[1]*cbar_scale)\n",
    "    plt.colorbar()\n",
    "    plt.axis('tight')\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd57c4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chan = 0\n",
    "inline_num = i_start_test+nil0+chan # leave for now, but will need to change when using multiple RGBA images / batches, chan handling will need to change\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 8), gridspec_kw={'width_ratios': [1,1,1]})\n",
    "    plt.rc('font', size=16)\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x_test[0,:,:,chan].T, cmap='RdYlBu', extent=(nxl0, nxl1, nt1, nt0), vmin=scale_range[0], vmax=scale_range[1])\n",
    "    plt.title(r'Kerry3D')\n",
    "    plt.axis('tight')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Clean_images_list[i][0,:,:,chan].T, cmap='RdYlBu', extent=(nxl0, nxl1, nt1, nt0),\n",
    "               vmin=scale_range[0], vmax=scale_range[1]\n",
    "              )\n",
    "    plt.title(r'Denoised')\n",
    "    plt.axis('tight')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(Difference_list[i][0,:,:,chan].T, cmap='RdYlBu', extent=(nxl0, nxl1, nt1, nt0),\n",
    "    #            vmin=scale_range[0], vmax=scale_range[1]\n",
    "#                vmin=-0.03, vmax=0.03\n",
    "               vmin=-0.06, vmax=0.06\n",
    "              )\n",
    "    plt.title('Noise Removed')\n",
    "    plt.axis('tight')\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    plt.suptitle(f'{load_version} Inline {inline_num} Epoch {epochs[i]}')\n",
    "    fig.tight_layout()\n",
    "    plt.gray()\n",
    "\n",
    "    plt.savefig(f'Unet_{load_version}_3panel_chan{chan}_epoch_{epochs[i]}.png')\n",
    "    plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbfdb5",
   "metadata": {},
   "source": [
    "# Train the loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfcd7b",
   "metadata": {},
   "source": [
    "### Prep Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "version = 'test'\n",
    "\n",
    "pathstart = './Logs/checkpoints_{}/'.format(version)\n",
    "pathend = 'ckpt-{epoch:02d}.hdf5'\n",
    "ckpt_filepath = pathstart + pathend\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath,\n",
    "    # save_weights_only=False,\n",
    "    save_weights_only=True,\n",
    "    monitor=('loss'),\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    verbose=1,\n",
    "    save_best_only=False, # want to save full model every x epochs to print image\n",
    ")\n",
    "\n",
    "tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=f'./Logs/TBlog_{version}', write_graph=True, write_images=True)\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(f'./Logs/csvlog_{version}.csv', separator=',', append=False)\n",
    "# early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339bc27",
   "metadata": {},
   "source": [
    "### Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2169574",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='mse') # loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31cc8b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(loaded_model, to_file= f'./{version}_arch.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    history=loaded_model.fit(x_train, x_train,\n",
    "                    epochs=1000,\n",
    "#                 epochs=5000,\n",
    "#                 batch_size=2,        # c.f. discussion on batch size\n",
    "                    batch_size=1,\n",
    "                    shuffle=True,        # shuffles whole dataset, not within batches\n",
    "#                 shuffle=False,\n",
    "                    validation_data=(x_train, x_train),   # What goes into the loss function each epoch.\n",
    "                    callbacks=[\n",
    "                        model_checkpoint_callback,\n",
    "                        tensor_board_callback,\n",
    "                        csvlogger_callback,\n",
    "#                     early_stopping_callback,\n",
    "                    ])\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time-start_time\n",
    "print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e456ff",
   "metadata": {},
   "source": [
    "# Visualize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1076f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,6))\n",
    "ax = axes[0]\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend(['train', 'test'], loc='upper left')\n",
    "ax = axes[1]\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend(['train', 'test'], loc='upper left')\n",
    "plt.suptitle(f'Unet_{load_version}_loss')\n",
    "\n",
    "# plt.savefig(f'Unet_{load_version}_loss_RR.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48319cdf",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "Unet1_json = loaded_model.to_json()\n",
    "with open(f\"Unet_{version}.1.json\", \"w\") as json_file:\n",
    "    json_file.write(Unet1_json)\n",
    "# serialize weights to HDF5\n",
    "loaded_model.save_weights(f\"Unet_{version}.1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c965ede",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fe64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0 # BE MINDFUL OF WHAT THIS NUMBER MEANS GIVEN THE NORMALIZATION\n",
    "noise_stdev = 1.0\n",
    "# x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=noise_stdev, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.5, scale=noise_stdev, size=x_test.shape)\n",
    "\n",
    "print(np.shape(x_train_noisy))\n",
    "print(np.shape(x_test_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_images= loaded_model.predict(x_test)\n",
    "Clean_images=np.reshape(Clean_images,(4,732,1252))\n",
    "# Clean_images=np.reshape(Clean_images,(4,732,1252))\n",
    "Clean_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428a509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be91d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(1, 4):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    #Clean_images=Clean_images.reshape(4,732, 1252)\n",
    "    plt.imshow(Clean_images[i].T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb33864",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.reshape(x_test, (4,732,1252))\n",
    "x_test_noisy=np.reshape(x_test_noisy, (4,732,1252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9010c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x_test[3].T)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(x_test_noisy[3].T)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Clean_images[3].T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc9e49",
   "metadata": {},
   "source": [
    "# Visualize the removed noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d96afe",
   "metadata": {},
   "source": [
    "Needs more training. clear geology removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113654cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "Difference= x_test_noisy[3] - Clean_images[3]\n",
    "plt.imshow(Difference.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ec220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "Difference= x_test[0] - Clean_images[0]\n",
    "plt.imshow(Difference.T, cmap='RdYlBu', extent=(nxl0, nxl1, nt1, nt0), vmin=-0.02, vmax=0.02)\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.title('Noise Removed')\n",
    "# plt.savefig(f'Unet_{version}_noise.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b5679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
